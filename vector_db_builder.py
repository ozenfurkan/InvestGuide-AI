import json
from pathlib import Path
from typing import List, Dict, Any, Iterator
import shutil

from langchain.schema import Document
from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings
from dotenv import load_dotenv
import os

# Sabitler
DATA_PATH = Path("data")
DB_PATH = "mevzuat_veritabani" # FAISS klasÃ¶r olarak kaydeder
MEVZUAT_DOSYASI = "karar_2012_3305_son_versiyon.json"

def _serialize_recursive(data: Any) -> Iterator[str]:
    """
    KarmaÅŸÄ±k ve iÃ§ iÃ§e geÃ§miÅŸ JSON yapÄ±larÄ±ndan (sÃ¶zlÃ¼kler, listeler)
    anlamlÄ± metin parÃ§alarÄ± Ã¼reten yardÄ±mcÄ± bir generator fonksiyonu.
    """
    if isinstance(data, dict):
        for key, value in data.items():
            # AnahtarlarÄ± baÅŸlÄ±k gibi kullanarak okunabilirliÄŸi artÄ±r
            processed_key = key.replace("_", " ").replace("-", " ").title()
            # DeÄŸeri de Ã¶zyineli olarak iÅŸle
            for sub_value in _serialize_recursive(value):
                # Sadece metin iÃ§eren anahtarlarÄ± deÄŸil, tÃ¼m yapÄ±yÄ± metne dÃ¶k
                # Ã–rn: "Ä°l AdÄ±: Adana", "SektÃ¶r NumaralarÄ±: 1 2 3"
                if sub_value and not sub_value.isspace():
                     # Basit anahtar-deÄŸer Ã§iftleri iÃ§in daha temiz format
                    if not any(isinstance(v, (dict, list)) for v in data.values()):
                         yield f"{processed_key}: {sub_value}"
                         break # AynÄ± seviyedeki diÄŸer anahtarlara geÃ§
                    else:
                         yield sub_value

    elif isinstance(data, list):
        for item in data:
            yield from _serialize_recursive(item)
    elif data is not None:
        yield str(data).strip()

def load_documents_from_decision(file_path: Path) -> List[Document]:
    """
    Belirtilen Karar JSON dosyasÄ±nÄ± yÃ¼kler. Hem 'maddeler'i hem de 'ekler'i
    kendi yapÄ±larÄ±na uygun, bÃ¼tÃ¼ncÃ¼l ve ayrÄ± Document nesneleri olarak iÅŸler.
    """
    all_documents = []
    print(f"-> Nihai Ä°ÅŸleme: {file_path.name}")
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)

        # 1. Maddeleri Ä°ÅŸle
        maddeler_listesi = data.get("maddeler", [])
        if maddeler_listesi:
            for madde in maddeler_listesi:
                baslik = madde.get("baÅŸlÄ±k", "BaÅŸlÄ±ksÄ±z Madde")
                madde_no = madde.get("maddeNo", "")
                
                # FÄ±kra ve bentlerden tam metni birleÅŸtir
                content_parts = list(_serialize_recursive(madde.get("fÄ±kralar", [])))
                if not content_parts:
                    continue
                
                page_content = f"Madde No: {madde_no} - BaÅŸlÄ±k: {baslik}\n\n" + "\n".join(content_parts)
                doc = Document(page_content=page_content, metadata={"source": file_path.name, "kategori": "Madde", "detay": f"Madde {madde_no}"})
                all_documents.append(doc)
            print(f"  + {len(maddeler_listesi)} madde baÅŸarÄ±yla ayrÄ±ÅŸtÄ±rÄ±ldÄ±.")

        # 2. Ekleri Ä°ÅŸle
        ekler_listesi = data.get("ekler", [])
        if ekler_listesi:
            for ek in ekler_listesi:
                baslik = ek.get("baslik", "BaÅŸlÄ±ksÄ±z Ek")
                ek_no = ek.get("ekNo", "")

                # KarmaÅŸÄ±k ek iÃ§eriÄŸini okunabilir bir metne dÃ¶nÃ¼ÅŸtÃ¼r
                content_parts = list(_serialize_recursive(ek.get("icerik", ek)))
                if not content_parts:
                    continue

                page_content = f"Ek No: {ek_no} - BaÅŸlÄ±k: {baslik}\n\n" + "\n".join(content_parts)
                doc = Document(page_content=page_content, metadata={"source": file_path.name, "kategori": "Ek", "detay": f"Ek {ek_no}"})
                all_documents.append(doc)
            print(f"  + {len(ekler_listesi)} ek baÅŸarÄ±yla ayrÄ±ÅŸtÄ±rÄ±ldÄ±.")

    except (FileNotFoundError, json.JSONDecodeError) as e:
        print(f"  - HATA: Dosya okunamadÄ± veya JSON formatÄ± bozuk. {e}")
            
    return all_documents

def build_vector_db():
    """
    Mevzuat metinlerini iÅŸleyerek bir FAISS vektÃ¶r veritabanÄ± oluÅŸturur ve kaydeder.
    """
    print("\n--- VektÃ¶r VeritabanÄ± OluÅŸturma (FAISS StandardÄ±) ---")
    db_path_obj = Path(DB_PATH)
    if db_path_obj.exists():
        print(f"\nğŸ§¹ Mevcut veritabanÄ± '{DB_PATH}' temizleniyor...")
        shutil.rmtree(db_path_obj)

    documents = load_documents_from_decision(DATA_PATH / MEVZUAT_DOSYASI)
    
    if not documents:
        print("\nâŒ Ä°ÅŸlenecek dokÃ¼man bulunamadÄ±. LÃ¼tfen JSON yapÄ±sÄ±nÄ± kontrol edin.")
        return

    print(f"\nToplam {len(documents)} adet bÃ¼tÃ¼ncÃ¼l dokÃ¼man (madde/ek) yÃ¼klendi.")
    
    print("\nğŸ§  Metinler vektÃ¶rlere dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼yor ve FAISS indexi oluÅŸturuluyor...")
    embeddings = OpenAIEmbeddings()
    vector_db = FAISS.from_documents(documents, embeddings)
    
    vector_db.save_local(DB_PATH)
    print(f"\nâœ¨ FAISS veritabanÄ± baÅŸarÄ±yla oluÅŸturuldu: '{DB_PATH}'")

if __name__ == "__main__":
    load_dotenv()
    if not os.getenv("OPENAI_API_KEY"):
        raise ValueError("LÃ¼tfen projenin kÃ¶k dizininde OPENAI_API_KEY'i iÃ§eren bir .env dosyasÄ± oluÅŸturun.")
    build_vector_db()